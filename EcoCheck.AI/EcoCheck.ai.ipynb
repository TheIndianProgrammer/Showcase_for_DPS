{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > ## About This Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We all know almost all competitive companies in the world right now, have business models\n",
    "that make them the most profit as possible. To cut costs and increase profit margins\n",
    "companies don’t invest resources on things like safety, environmental impacts etc. The\n",
    "negligence for environmental impact research of company’s products can lead to\n",
    "Environment destruction and Environmental degradation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data():\n",
    "\n",
    "    df = pd.read_csv(\"Dataset.csv\",header=None)\n",
    "    names = [\"Metals\", \"Plastics\",\"Electronics\",\"Hazardous Liquids and Substances\",\"Ceramics\",\"Impact\"]\n",
    "    df.columns = names\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding The Labels Through Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode(df):\n",
    "    df_labelled = df.copy()\n",
    "\n",
    "    label_encode = {\"Impact\": {\"High\":0, \"Moderate\":1, \"Low\":2}}\n",
    "\n",
    "    df_labelled.replace(label_encode,inplace=True)\n",
    "    return df_labelled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding The Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Metals  Plastics  Electronics  Hazardous Liquids and Substances  Ceramics  \\\n",
      "0     100         0            0                                 0         0   \n",
      "1      99         0            0                                 0         0   \n",
      "2      98         0            0                                 0         0   \n",
      "3      97         0            0                                 0         0   \n",
      "4      96         0            0                                 0         0   \n",
      "\n",
      "   Impact  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n"
     ]
    }
   ],
   "source": [
    "df = import_data()\n",
    "df = label_encode(df)\n",
    "\n",
    "x_values = df[[\"Metals\", \"Plastics\",\"Electronics\",\"Hazardous Liquids and Substances\",\"Ceramics\",\"Impact\"]]\n",
    "print(x_values.head())\n",
    "\n",
    "standardise = StandardScaler()\n",
    "x_values = standardise.fit_transform(x_values)\n",
    "x_values_df = pd.DataFrame(x_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the rting The Libraries 'Keras' And 'Tensorfolwlow'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(6,input_dim=6,activation='relu'))\n",
    "model.add(Dense(6,activation='relu')) \n",
    "model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 105\n",
      "Trainable params: 105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label_encode = {\"Impact\": {\"High\":0, \"Moderate\":1, \"Low\":2}}\n",
    "\n",
    "df.replace(label_encode,inplace=True)\n",
    "\n",
    "y_values = df['Impact']\n",
    "\n",
    "y_values = to_categorical(y_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "654/654 [==============================] - 2s 3ms/step - loss: 0.7848 - accuracy: 0.6896\n",
      "Epoch 2/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.3889 - accuracy: 0.8700\n",
      "Epoch 3/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.1427 - accuracy: 0.9862\n",
      "Epoch 4/100\n",
      "654/654 [==============================] - 2s 3ms/step - loss: 0.0438 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "654/654 [==============================] - 2s 3ms/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "654/654 [==============================] - 2s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "654/654 [==============================] - 2s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "654/654 [==============================] - 2s 3ms/step - loss: 7.8320e-04 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "654/654 [==============================] - 2s 3ms/step - loss: 4.7439e-04 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "654/654 [==============================] - 2s 3ms/step - loss: 2.8778e-04 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "654/654 [==============================] - 2s 3ms/step - loss: 1.8298e-04 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 1.1861e-04 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 7.9252e-05 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 5.3336e-05 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 3.6183e-05 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 2.4686e-05 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 1.5878e-05 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 9.8496e-06 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 6.4495e-06 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 4.3393e-06 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 2.9831e-06 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 2.0667e-06 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 1.4378e-06 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 9.9614e-07 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 6.9010e-07 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 4.7684e-07 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 3.2974e-07 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 2.2949e-07 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 1.6259e-07 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 1.0335e-07 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 6.2886e-08 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 4.1195e-08 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 2.6612e-08 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 1.8228e-08 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 1.1119e-08 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 4.9215e-09 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 3.6455e-10 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "654/654 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "654/654 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1731e8efe50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_values,y_values,epochs=100,shuffle=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in x_train: 457\n",
      "Number of rows in x_test: 197\n",
      "Number of rows in y_train: 457\n",
      "Number of rows in y_test: 197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_values = df[[\"Metals\", \"Plastics\",\"Electronics\",\"Hazardous Liquids and Substances\",\"Ceramics\"]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_values,y_values,test_size=0.3,random_state=10)\n",
    "\n",
    "# Check the number of rows in x_train, x_test, y_train and y_test\n",
    "print(\"Number of rows in x_train:\", x_train.shape[0])\n",
    "print(\"Number of rows in x_test:\", x_test.shape[0])\n",
    "print(\"Number of rows in y_train:\", y_train.shape[0])\n",
    "print(\"Number of rows in y_test:\", y_test.shape[0])\n",
    "\n",
    "standardise = StandardScaler()\n",
    "\n",
    "x_train = standardise.fit_transform(x_train)\n",
    "x_test = standardise.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 6)                 36        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 99\n",
      "Trainable params: 99\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_val = Sequential()\n",
    "\n",
    "model_val.add(Dense(6,input_dim=5,activation='relu'))\n",
    "model_val.add(Dense(6,activation='relu'))\n",
    "model_val.add(Dense(3,activation='softmax'))\n",
    "\n",
    "model_val.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "print(model_val.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "457/457 [==============================] - 2s 2ms/step - loss: 1.0667 - accuracy: 0.4004 - val_loss: 0.9973 - val_accuracy: 0.4213\n",
      "Epoch 2/120\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.9467 - accuracy: 0.4464 - val_loss: 0.8952 - val_accuracy: 0.5127\n",
      "Epoch 3/120\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.8527 - accuracy: 0.6433 - val_loss: 0.8032 - val_accuracy: 0.6701\n",
      "Epoch 4/120\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.7398 - accuracy: 0.7396 - val_loss: 0.6883 - val_accuracy: 0.7462\n",
      "Epoch 5/120\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.6087 - accuracy: 0.7834 - val_loss: 0.5685 - val_accuracy: 0.8325\n",
      "Epoch 6/120\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.5138 - accuracy: 0.8534 - val_loss: 0.4779 - val_accuracy: 0.8731\n",
      "Epoch 7/120\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.4454 - accuracy: 0.8862 - val_loss: 0.4220 - val_accuracy: 0.9188\n",
      "Epoch 8/120\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3936 - accuracy: 0.9278 - val_loss: 0.3577 - val_accuracy: 0.9391\n",
      "Epoch 9/120\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.3560 - accuracy: 0.9344 - val_loss: 0.3240 - val_accuracy: 0.9391\n",
      "Epoch 10/120\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.3206 - accuracy: 0.9365 - val_loss: 0.2829 - val_accuracy: 0.9492\n",
      "Epoch 11/120\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.2924 - accuracy: 0.9540 - val_loss: 0.2599 - val_accuracy: 0.9543\n",
      "Epoch 12/120\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.2695 - accuracy: 0.9562 - val_loss: 0.2302 - val_accuracy: 0.9594\n",
      "Epoch 13/120\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.2503 - accuracy: 0.9540 - val_loss: 0.2125 - val_accuracy: 0.9594\n",
      "Epoch 14/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.2347 - accuracy: 0.9584 - val_loss: 0.1949 - val_accuracy: 0.9594\n",
      "Epoch 15/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.2219 - accuracy: 0.9628 - val_loss: 0.1717 - val_accuracy: 0.9746\n",
      "Epoch 16/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.2094 - accuracy: 0.9716 - val_loss: 0.1575 - val_accuracy: 0.9797\n",
      "Epoch 17/120\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.2029 - accuracy: 0.9628 - val_loss: 0.1471 - val_accuracy: 0.9797\n",
      "Epoch 18/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1929 - accuracy: 0.9716 - val_loss: 0.1508 - val_accuracy: 0.9594\n",
      "Epoch 19/120\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.1856 - accuracy: 0.9781 - val_loss: 0.1434 - val_accuracy: 0.9594\n",
      "Epoch 20/120\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.1809 - accuracy: 0.9628 - val_loss: 0.1292 - val_accuracy: 0.9746\n",
      "Epoch 21/120\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.1760 - accuracy: 0.9650 - val_loss: 0.1307 - val_accuracy: 0.9645\n",
      "Epoch 22/120\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.1717 - accuracy: 0.9628 - val_loss: 0.1169 - val_accuracy: 0.9746\n",
      "Epoch 23/120\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.1678 - accuracy: 0.9584 - val_loss: 0.1077 - val_accuracy: 0.9848\n",
      "Epoch 24/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1613 - accuracy: 0.9650 - val_loss: 0.1081 - val_accuracy: 0.9695\n",
      "Epoch 25/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1599 - accuracy: 0.9716 - val_loss: 0.1058 - val_accuracy: 0.9746\n",
      "Epoch 26/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1541 - accuracy: 0.9759 - val_loss: 0.0945 - val_accuracy: 0.9797\n",
      "Epoch 27/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1508 - accuracy: 0.9737 - val_loss: 0.1000 - val_accuracy: 0.9645\n",
      "Epoch 28/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1475 - accuracy: 0.9781 - val_loss: 0.0920 - val_accuracy: 0.9797\n",
      "Epoch 29/120\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.1440 - accuracy: 0.9759 - val_loss: 0.0854 - val_accuracy: 0.9746\n",
      "Epoch 30/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1409 - accuracy: 0.9803 - val_loss: 0.0816 - val_accuracy: 0.9898\n",
      "Epoch 31/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1399 - accuracy: 0.9781 - val_loss: 0.0812 - val_accuracy: 0.9848\n",
      "Epoch 32/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1371 - accuracy: 0.9759 - val_loss: 0.0747 - val_accuracy: 0.9797\n",
      "Epoch 33/120\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.1378 - accuracy: 0.9847 - val_loss: 0.0763 - val_accuracy: 0.9797\n",
      "Epoch 34/120\n",
      "457/457 [==============================] - 3s 8ms/step - loss: 0.1348 - accuracy: 0.9803 - val_loss: 0.0744 - val_accuracy: 0.9797\n",
      "Epoch 35/120\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.1324 - accuracy: 0.9737 - val_loss: 0.0717 - val_accuracy: 0.9898\n",
      "Epoch 36/120\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.1304 - accuracy: 0.9781 - val_loss: 0.0785 - val_accuracy: 0.9746\n",
      "Epoch 37/120\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.1279 - accuracy: 0.9847 - val_loss: 0.0707 - val_accuracy: 0.9898\n",
      "Epoch 38/120\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.1275 - accuracy: 0.9759 - val_loss: 0.0778 - val_accuracy: 0.9695\n",
      "Epoch 39/120\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.1274 - accuracy: 0.9759 - val_loss: 0.0697 - val_accuracy: 0.9848\n",
      "Epoch 40/120\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.1257 - accuracy: 0.9825 - val_loss: 0.0649 - val_accuracy: 0.9848\n",
      "Epoch 41/120\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.1246 - accuracy: 0.9847 - val_loss: 0.0708 - val_accuracy: 0.9797\n",
      "Epoch 42/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1254 - accuracy: 0.9737 - val_loss: 0.0631 - val_accuracy: 0.9848\n",
      "Epoch 43/120\n",
      "457/457 [==============================] - 2s 3ms/step - loss: 0.1261 - accuracy: 0.9759 - val_loss: 0.0635 - val_accuracy: 0.9848\n",
      "Epoch 44/120\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.1254 - accuracy: 0.9650 - val_loss: 0.0695 - val_accuracy: 0.9797\n",
      "Epoch 45/120\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.1184 - accuracy: 0.9825 - val_loss: 0.0607 - val_accuracy: 0.9898\n",
      "Epoch 46/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1223 - accuracy: 0.9716 - val_loss: 0.0661 - val_accuracy: 0.9746\n",
      "Epoch 47/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1211 - accuracy: 0.9825 - val_loss: 0.0621 - val_accuracy: 0.9898\n",
      "Epoch 48/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1187 - accuracy: 0.9803 - val_loss: 0.0623 - val_accuracy: 0.9898\n",
      "Epoch 49/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1168 - accuracy: 0.9847 - val_loss: 0.0698 - val_accuracy: 0.9797\n",
      "Epoch 50/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1195 - accuracy: 0.9759 - val_loss: 0.0599 - val_accuracy: 0.9797\n",
      "Epoch 51/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1151 - accuracy: 0.9825 - val_loss: 0.0696 - val_accuracy: 0.9797\n",
      "Epoch 52/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1171 - accuracy: 0.9825 - val_loss: 0.0577 - val_accuracy: 0.9848\n",
      "Epoch 53/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1156 - accuracy: 0.9759 - val_loss: 0.0603 - val_accuracy: 0.9848\n",
      "Epoch 54/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1161 - accuracy: 0.9781 - val_loss: 0.0613 - val_accuracy: 0.9898\n",
      "Epoch 55/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1154 - accuracy: 0.9803 - val_loss: 0.0586 - val_accuracy: 0.9848\n",
      "Epoch 56/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1159 - accuracy: 0.9759 - val_loss: 0.0602 - val_accuracy: 0.9746\n",
      "Epoch 57/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1131 - accuracy: 0.9737 - val_loss: 0.0556 - val_accuracy: 0.9949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1117 - accuracy: 0.9825 - val_loss: 0.0604 - val_accuracy: 0.9848\n",
      "Epoch 59/120\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.1155 - accuracy: 0.9737 - val_loss: 0.0577 - val_accuracy: 0.9848\n",
      "Epoch 60/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1129 - accuracy: 0.9781 - val_loss: 0.0531 - val_accuracy: 0.9848\n",
      "Epoch 61/120\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.1132 - accuracy: 0.9759 - val_loss: 0.0580 - val_accuracy: 0.9797\n",
      "Epoch 62/120\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.1117 - accuracy: 0.9759 - val_loss: 0.0576 - val_accuracy: 0.9797\n",
      "Epoch 63/120\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.1143 - accuracy: 0.9825 - val_loss: 0.0510 - val_accuracy: 0.9848\n",
      "Epoch 64/120\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.1115 - accuracy: 0.9759 - val_loss: 0.0550 - val_accuracy: 0.9797\n",
      "Epoch 65/120\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.1104 - accuracy: 0.9803 - val_loss: 0.0558 - val_accuracy: 0.9848\n",
      "Epoch 66/120\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.1106 - accuracy: 0.9803 - val_loss: 0.0530 - val_accuracy: 0.9848\n",
      "Epoch 67/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1069 - accuracy: 0.9847 - val_loss: 0.0664 - val_accuracy: 0.9746\n",
      "Epoch 68/120\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.1102 - accuracy: 0.9803 - val_loss: 0.0596 - val_accuracy: 0.9898\n",
      "Epoch 69/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1127 - accuracy: 0.9803 - val_loss: 0.0574 - val_accuracy: 0.9949\n",
      "Epoch 70/120\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.1082 - accuracy: 0.9781 - val_loss: 0.0629 - val_accuracy: 0.9746\n",
      "Epoch 71/120\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.1053 - accuracy: 0.9781 - val_loss: 0.0563 - val_accuracy: 0.9848\n",
      "Epoch 72/120\n",
      "457/457 [==============================] - 1s 2ms/step - loss: 0.1096 - accuracy: 0.9803 - val_loss: 0.0495 - val_accuracy: 0.9898\n",
      "Epoch 73/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1104 - accuracy: 0.9781 - val_loss: 0.0492 - val_accuracy: 0.9848\n",
      "Epoch 74/120\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.1054 - accuracy: 0.9825 - val_loss: 0.0561 - val_accuracy: 0.9797\n",
      "Epoch 75/120\n",
      "457/457 [==============================] - 3s 6ms/step - loss: 0.1083 - accuracy: 0.9759 - val_loss: 0.0508 - val_accuracy: 0.9797\n",
      "Epoch 76/120\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.1067 - accuracy: 0.9759 - val_loss: 0.0544 - val_accuracy: 0.9848\n",
      "Epoch 77/120\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.1045 - accuracy: 0.9825 - val_loss: 0.0535 - val_accuracy: 0.9848\n",
      "Epoch 78/120\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.1081 - accuracy: 0.9716 - val_loss: 0.0476 - val_accuracy: 0.9797\n",
      "Epoch 79/120\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.1053 - accuracy: 0.9847 - val_loss: 0.0528 - val_accuracy: 0.9848\n",
      "Epoch 80/120\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.1071 - accuracy: 0.9803 - val_loss: 0.0513 - val_accuracy: 0.9898\n",
      "Epoch 81/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1027 - accuracy: 0.9759 - val_loss: 0.0561 - val_accuracy: 0.9898\n",
      "Epoch 82/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1036 - accuracy: 0.9781 - val_loss: 0.0510 - val_accuracy: 0.9848\n",
      "Epoch 83/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1035 - accuracy: 0.9847 - val_loss: 0.0482 - val_accuracy: 0.9797\n",
      "Epoch 84/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1053 - accuracy: 0.9781 - val_loss: 0.0527 - val_accuracy: 0.9848\n",
      "Epoch 85/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1023 - accuracy: 0.9803 - val_loss: 0.0477 - val_accuracy: 0.9898\n",
      "Epoch 86/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1031 - accuracy: 0.9781 - val_loss: 0.0511 - val_accuracy: 0.9949\n",
      "Epoch 87/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1024 - accuracy: 0.9737 - val_loss: 0.0481 - val_accuracy: 0.9898\n",
      "Epoch 88/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1035 - accuracy: 0.9781 - val_loss: 0.0493 - val_accuracy: 0.9848\n",
      "Epoch 89/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1027 - accuracy: 0.9825 - val_loss: 0.0535 - val_accuracy: 0.9848\n",
      "Epoch 90/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1003 - accuracy: 0.9781 - val_loss: 0.0492 - val_accuracy: 0.9898\n",
      "Epoch 91/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0993 - accuracy: 0.9847 - val_loss: 0.0591 - val_accuracy: 0.9797\n",
      "Epoch 92/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1031 - accuracy: 0.9759 - val_loss: 0.0521 - val_accuracy: 0.9949\n",
      "Epoch 93/120\n",
      "457/457 [==============================] - 2s 5ms/step - loss: 0.1025 - accuracy: 0.9803 - val_loss: 0.0565 - val_accuracy: 0.9797\n",
      "Epoch 94/120\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.1008 - accuracy: 0.9803 - val_loss: 0.0584 - val_accuracy: 0.9848\n",
      "Epoch 95/120\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.1012 - accuracy: 0.9781 - val_loss: 0.0492 - val_accuracy: 0.9848\n",
      "Epoch 96/120\n",
      "457/457 [==============================] - 2s 4ms/step - loss: 0.1014 - accuracy: 0.9781 - val_loss: 0.0512 - val_accuracy: 0.9848\n",
      "Epoch 97/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1013 - accuracy: 0.9825 - val_loss: 0.0478 - val_accuracy: 0.9898\n",
      "Epoch 98/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0963 - accuracy: 0.9825 - val_loss: 0.0498 - val_accuracy: 0.9797\n",
      "Epoch 99/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0980 - accuracy: 0.9891 - val_loss: 0.0516 - val_accuracy: 0.9797\n",
      "Epoch 100/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1007 - accuracy: 0.9781 - val_loss: 0.0520 - val_accuracy: 0.9797\n",
      "Epoch 101/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1001 - accuracy: 0.9803 - val_loss: 0.0498 - val_accuracy: 0.9848\n",
      "Epoch 102/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1010 - accuracy: 0.9759 - val_loss: 0.0457 - val_accuracy: 0.9848\n",
      "Epoch 103/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0988 - accuracy: 0.9803 - val_loss: 0.0499 - val_accuracy: 0.9898\n",
      "Epoch 104/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0990 - accuracy: 0.9825 - val_loss: 0.0479 - val_accuracy: 0.9898\n",
      "Epoch 105/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0967 - accuracy: 0.9825 - val_loss: 0.0472 - val_accuracy: 0.9949\n",
      "Epoch 106/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.1008 - accuracy: 0.9825 - val_loss: 0.0416 - val_accuracy: 0.9949\n",
      "Epoch 107/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0974 - accuracy: 0.9847 - val_loss: 0.0502 - val_accuracy: 0.9898\n",
      "Epoch 108/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0975 - accuracy: 0.9781 - val_loss: 0.0433 - val_accuracy: 0.9848\n",
      "Epoch 109/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0943 - accuracy: 0.9803 - val_loss: 0.0457 - val_accuracy: 0.9848\n",
      "Epoch 110/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0982 - accuracy: 0.9825 - val_loss: 0.0527 - val_accuracy: 0.9898\n",
      "Epoch 111/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0983 - accuracy: 0.9847 - val_loss: 0.0485 - val_accuracy: 0.9898\n",
      "Epoch 112/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0997 - accuracy: 0.9781 - val_loss: 0.0421 - val_accuracy: 0.9949\n",
      "Epoch 113/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0974 - accuracy: 0.9803 - val_loss: 0.0422 - val_accuracy: 0.9848\n",
      "Epoch 114/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0953 - accuracy: 0.9803 - val_loss: 0.0446 - val_accuracy: 0.9848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0966 - accuracy: 0.9803 - val_loss: 0.0487 - val_accuracy: 0.9848\n",
      "Epoch 116/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0991 - accuracy: 0.9716 - val_loss: 0.0477 - val_accuracy: 0.9848\n",
      "Epoch 117/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0977 - accuracy: 0.9781 - val_loss: 0.0514 - val_accuracy: 0.9848\n",
      "Epoch 118/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0969 - accuracy: 0.9781 - val_loss: 0.0526 - val_accuracy: 0.9848\n",
      "Epoch 119/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0947 - accuracy: 0.9737 - val_loss: 0.0406 - val_accuracy: 0.9898\n",
      "Epoch 120/120\n",
      "457/457 [==============================] - 1s 3ms/step - loss: 0.0956 - accuracy: 0.9825 - val_loss: 0.0424 - val_accuracy: 0.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17326dcf7c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_val.fit(x_train,y_train,epochs=120,shuffle=True,validation_data=(x_test,y_test), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"Dataset 1 (Iris.data) - Version 2.5.1 (5 columns).csv\",header=None)\n",
    "names = [\"Metals\", \"Plastics\",\"Electronics\",\"Hazardous Liquids and Substances\",\"Ceramics\",\"Impact\"]\n",
    "df2.columns = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encode = {\"Impact\": {\"High\":0, \"Moderate\":1, \"Low\":2}}\n",
    "\n",
    "# Use .replace to change the different classes into numbers\n",
    "df2.replace(label_encode,inplace=True)\n",
    "\n",
    "x_val = df2[[\"Metals\", \"Plastics\",\"Electronics\",\"Hazardous Liquids and Substances\",\"Ceramics\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_stand = standardise.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9998522e-01 8.2035015e-08 1.4667148e-05]\n",
      " [9.9998534e-01 1.3929871e-07 1.4537501e-05]\n",
      " [9.9998534e-01 2.3653219e-07 1.4409039e-05]\n",
      " ...\n",
      " [6.5905642e-04 9.2999003e-04 9.9841094e-01]\n",
      " [2.1383716e-03 4.2739254e-03 9.9358773e-01]\n",
      " [7.2374619e-03 7.2654456e-02 9.2010808e-01]]\n"
     ]
    }
   ],
   "source": [
    "y_val = model_val.predict(x_val_stand)\n",
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "raw_output = []\n",
    "for ii in range(0,y_val.shape[0]):\n",
    "    raw_output.append(np.argmax(y_val[ii,:]))\n",
    "print(raw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'Low', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'High', 'High', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Moderate', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Moderate', 'Moderate', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Moderate', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Moderate', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Moderate', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low', 'Low']\n"
     ]
    }
   ],
   "source": [
    "mapping = {\n",
    "    0: 'High',\n",
    "    1: 'Moderate',\n",
    "    2: 'Low',\n",
    "}\n",
    "final_output = [mapping.get(word, word) for word in raw_output]\n",
    "print(final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation competed succsesfull !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(input_data):\n",
    "\n",
    "    label_encode = {\"Impact\": {\"High\":0, \"Moderate\":1, \"Low\":2}}\n",
    "    input_data.replace(label_encode,inplace=True)\n",
    "    x_new_predict = input_data[[\"Metals\", \"Plastics\",\"Electronics\",\"Hazardous Liquids and Substances\",\"Ceramics\"]]\n",
    "    x_predict = standardise.transform(x_new_predict)\n",
    "    y_new_predict = model_val.predict(x_predict)\n",
    "    \n",
    "    raw_output_pred = []\n",
    "    raw_output_pred.append(np.argmax(y_new_predict))\n",
    "    \n",
    "    mapping = {\n",
    "            0: 'High',\n",
    "            1: 'Moderate',\n",
    "            2: 'Low'}\n",
    "    \n",
    "    final_output1 = [mapping.get(num, num) for num in raw_output_pred]\n",
    "    \n",
    "    return final_output1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InterFace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataFrame(input_list):\n",
    "\n",
    "    input_dataFrame = pd.DataFrame(columns = [\"Metals\", \"Plastics\",\"Electronics\",\"Hazardous Liquids and Substances\",\"Ceramics\"])\n",
    "    input_dataFrame.loc[len(input_dataFrame)] = input_list\n",
    "    \n",
    "    return input_dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values():\n",
    "    \n",
    "    input_list =[]\n",
    "    \n",
    "    Metal_Val = float(input(\"Enter % of Metal in the Product: \"))\n",
    "    input_list.append(Metal_Val)\n",
    "    \n",
    "    Plastic_Val = float(input(\"Enter % of Plastics in the Product: \"))\n",
    "    input_list.append(Plastic_Val)\n",
    "    \n",
    "    E_Val = float(input(\"Enter % of Electronics in the Product: \"))\n",
    "    input_list.append(E_Val)\n",
    "\n",
    "    H_Val = float(input(\"Enter % of Hazordous Liquids and Substances in the Product: \"))\n",
    "    input_list.append(H_Val)\n",
    "    \n",
    "    Cera_Val = float(input(\"Enter % of Ceramics in the Product: \"))\n",
    "    input_list.append(Cera_Val)\n",
    "    \n",
    "    if sum(input_list) > 100:\n",
    "        print(\"Error: Incorrect Values entered (Values excead 100%)\")\n",
    "        \n",
    "    else:\n",
    "        return input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Choose an Option:********* \n",
      "0: Use Command Line Interface\n",
      "1: To exit\n",
      "Enter choice:0\n",
      ":============-EcoCheck.ai-=============:\n",
      "Starting...\n",
      "\n",
      "===-Product Info-===\n",
      "(Enter % Values in scale of 10% = 1)\n",
      "\n",
      "Enter % of Metal in the Product: 100\n",
      "Enter % of Plastics in the Product: 0\n",
      "Enter % of Electronics in the Product: 0\n",
      "Enter % of Hazordous Liquids and Substances in the Product: 0\n",
      "Enter % of Ceramics in the Product: 0\n",
      "\n",
      "\n",
      "Predicted Environmental Impact is :  ['High']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"**********Choose an Option:********* \")\n",
    "print(\"0: Use Command Line Interface\")\n",
    "print(\"1: To exit\")\n",
    "\n",
    "while True :\n",
    "\n",
    "    choice = int(input(\"Enter choice:\"))\n",
    "\n",
    "\n",
    "\n",
    "    if choice == 0:\n",
    "        print(\":============-EcoCheck.ai-=============:\")\n",
    "        print(\"Starting...\\n\")\n",
    "        print(\"===-Product Info-===\")\n",
    "        print(\"(Enter % Values in scale of 10% = 1)\\n\")\n",
    "        \n",
    "        input_list = get_values()\n",
    "        \n",
    "        input_dataFrame = create_dataFrame(input_list)\n",
    "        output = prediction(input_dataFrame)\n",
    "                            \n",
    "        print(\"\\n\")\n",
    "        print(\"Predicted Environmental Impact is : \", output)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    elif choice == 1:\n",
    "        print(\"\\nExiting!\\n\")\n",
    "        break\n",
    "\n",
    "    elif choice not in (0,1):\n",
    "        print(\"Invalid option\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49c77dd538cfb1d7d6ab37a4fd8c7fd8f705cd19250e3da34cbb983b220e90d2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
